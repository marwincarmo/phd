---
title: "Beyond Average Scores: Identification of Consistent and Inconsistent Academic Achievement"
subtitle: "Quantitative Research Seminar"
author: "Marwin Carmo"
format: 
  revealjs:
    scrollable: true
    incremental: true
    code-tools: true
    code-copy: true
    code-line-numbers: true
    code-link: true
    preview-links: true
    slide-number: true
    self-contained: true
    fig-height: 4
    fig-width: 6
    fig-align: center
    margin-left: "0"
    margin-right: "0"
    width: 1400
    # height: 900
    footer: "Beyond Average Scores: Identification of Consistent and Inconsistent Academic Achievement"
    logo: "https://github.com/emoriebeck/psc290-data-viz-2022/raw/main/01-week1-intro/02-code/02-images/ucdavis_logo_blue.png"
editor: source
editor_options: 
  chunk_output_type: console
---

## Motivation

- Average performance does not provide information on the *consistency* of academic achievement over time or within a cluster.

- Consider two students with a final grade of 75% at the year's end:
  - One had scores ranging from 50% to 100%.
  - The other maintained a steady 75%.

- Inconsistent performance may reflect unaccounted factors influencing learning.

## Our approach

- Identify clustering units (students, classrooms, etc.) that exhibit unusually high or low consistency (residual variance) in academic achievement.

- Mixed effects location scale model (MELSM) can be used to model residual variances.

- We present an adaptation of the MELSM by means of shrinking random effects to their fixed effect using the Spike and Slab regularization

## MELSM

- Educational data is classically analyzed by means of multilevel or mixed effects models (MLM):
  - Schools are level-2 units and students' test scores are the level-1 units.

- MLM assumes constant residual variance (scale)

- MELSM include a sub-model to addresses potential differences in the residual variance.

- The unexplained residual variance might provide insights over and above the expected academic achievement
that is captured in the conditional means, or location parameter.

## MELSM

- MELSM does not model the residuals themselves but, instead, the error \textit{variance} $\boldsymbol{\varphi}$ from which the residuals are realized.

- MELSM \textit{simultaneously} estimate the means and the residual variance.

- The model specifies a classic multilevel model for the observed values, $y_{ij}$ for school $j$ and student $i$, and a multilevel model for the within-cluster residual variances $\sigma^2_{\epsilon_{ij}}$.

## Advantages of MELSM

- Account for possible correlations among location and scale effects.

- For example, the variability of student performance within a school can be modeled as a function of parental socioeconomic status.

- Overcomes the limitations of multi-stage approaches and outperform the classic mixed effects model in in- and out of sample performance.

---

The starting point is the standard linear mixed effects model for $i = 1,2,...,n_j$ students, and $j = 1, 2, \ldots, S$ schools, specified as


\begin{equation}
  \label{eq:mixedmodel-lvl1}
  \textrm{Level 1:} \quad y_{ij} = \beta_{0j} + \beta_{1j} X_{ij} + e_{ij}
\end{equation}

\begin{aligned}
  \label{eq:mixedmodel-lvl2}
  \textrm{Level 2:}\quad \beta_{0j} &= \gamma_{00} + \gamma_{01}W_j + u_{0j} \\
                       \beta_{1j} &= \gamma_{10} + \gamma_{11}W_j + u_{1j}
\end{aligned}

\begin{equation}
  \label{eq:bcov}
  \begin{pmatrix} u_0 \\ u_1 \end{pmatrix} \sim \mathcal{N}
    \begin{Bmatrix} 
        \begin{pmatrix} 0 \\ 0  \end{pmatrix},
        \begin{pmatrix} \tau^2_{u_{0}} \\ \tau_{u_{0}u_{1}} & \tau^2_{u_{1}}
        \end{pmatrix}
    \end{Bmatrix}
\end{equation}

\begin{equation}
  e_{ij} \sim \mathcal{N} (0, \sigma_{\epsilon}^2)
\end{equation}

---

Next, we introduce a scale model for the residual variance

\begin{equation}
  \label{eq:var-lvl1}
  \textrm{Level 1:} \quad \sigma^2_{\epsilon_{ij}} = \exp(\alpha_{0j} + \alpha_{1j}M_{ij})
\end{equation}

\begin{aligned}
  \label{eq:var-lvl2}
  \textrm{Level 2:}\quad \alpha_{0j} &= \eta_{00} + \eta_{01}P_j + t_{0j} \\
                       \alpha_{1j} &= \eta_{10} + \eta_{11}P_j + t_{1j}
\end{aligned}

---

The random effects from the *scale* and *location* of the model come from a multivariate Gaussian Normal distribution with zero means:

\begin{equation}
  \label{eq:random-cov}
  \textbf{v}=
  \begin{bmatrix} u_0 \\ u_1 \\ t_0 \\ t_1 \end{bmatrix} \sim \mathcal{N}
    \begin{Bmatrix} 
        \boldsymbol{0}=
        \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
        \boldsymbol{\Sigma}=
        \begin{bmatrix} \tau^2_{u_0} \\ 
                        \tau_{u_0u_1} & \tau^2_{u_1} \\
                        \tau_{u_0t_0} & \tau_{u_1t_0} & \tau^2_{t_0} \\
                        \tau_{u_0t_1} & \tau_{u_1t_1} & \tau_{t_0t_1} & \tau^2_{t_1}
        \end{bmatrix}
    \end{Bmatrix}
\end{equation}

---

- $\boldsymbol{\Sigma}$ can be decomposed into $\boldsymbol\Sigma = \boldsymbol{\tau}\boldsymbol{\Omega\tau}'$ to specify independent priors for each element of $\boldsymbol{\tau}$ and $\boldsymbol{\Omega}$.

- $\boldsymbol{\tau}$ is a diagonal matrix where the diagonal elements are the random-effect variances.

- $\boldsymbol{\Omega}$ is the correlation matrix that contains the covariances among all random effects.

## Cholesky transformation

\begin{equation}
\label{eq:cholesky_approach}
\textbf{L} = 
    \begin{pmatrix}
        1 & 0 & 0 & 0\\
        \rho_{u_0u_1} & \sqrt{1 - l^2_{21}} & 0 & 0 \\
        \rho_{u_0t_0} & \frac{\rho_{u_1t_0} - l_{21} l_{31}}{l_{22}} & \sqrt{1 - l^2_{31} - l^2_{32}} & 0\\
        \rho_{u_0t_1} & \frac{\rho_{u_1t_1} - l_{21} l_{41}}{l_{22}} & \frac{\rho_{t_0t_1} - l_{31} l_{41} - l_{32} l_{42}}{l_{33}} & \sqrt{1 - l^2_{41} - l^2_{42} - l^2_{43}}
    \end{pmatrix}
\end{equation}

---

If we multiply $\textbf{L}$ by the random effect standard deviations, $\boldsymbol{\tau}$, and scale it with a standard normally distributed $\boldsymbol{z}$, we obtain $\textbf{v}$

\begin{equation}
    \textbf{v} = \boldsymbol{\tau}\textbf{L}\boldsymbol{z}.
\end{equation}

\begin{equation}
\begin{aligned}
    u_{0j} &= \tau_{u_0}z^\mu_j\\
    u_{1j} &= \tau_{u_1}(\rho_{u_{0j}u_{1j}} + \sqrt{1-l_{21}^2})z^\mu_j\\
    t_{0j} &= \tau_{t_0}(\rho_{u_{0j}t_{0j}} + l_{32} + \sqrt{1-l_{31}^2-l_{32}^2})z^\sigma_j\\
    t_{1j} &= \tau_{t_1}(\rho_{u_{0j}t_{1j}} + l_{42} + l_{43} + \sqrt{1-l_{41}^2-l_{31}^2-l_{32}^2})z^\sigma_j
\end{aligned}
\end{equation}

---


## Variable selection

\begin{equation}
\begin{aligned}
    u_{0j} &= \tau_{u_0}z^\mu_j\\
    u_{1j} &= \tau_{u_1}(\rho_{u_{0j}u_{1j}} + \sqrt{1-l_{21}^2})z^\mu_j\\
    t_{0j} &= \tau_{t_0}\color{red}{\delta_j}(\rho_{u_{0j}t_{0j}} + l_{32} + \sqrt{1-l_{31}^2-l_{32}^2})z^\sigma_j\\
    t_{1j} &= \tau_{t_1}\color{red}{\delta_j}(\rho_{u_{0j}t_{1j}} + l_{42} + l_{43} + \sqrt{1-l_{41}^2-l_{31}^2-l_{32}^2})z^\sigma_j
\end{aligned}
\end{equation}


## The Spike-and-slab approach

::: columns
::: {.column width="50%"}

- A two component mixture
a. A "spike", that is a Dirac measure concentrated at zero.
b. A diffuse "slab" component surrounding zero.
:::

::: {.column width="50%"}
:::fragment
![Rouder et al. (2018)](rouder2018.png){fig-align="center" width=65%}
:::
:::
:::

::: {.notes}
A Dirac measure is a measure whose (unit) mass is concentrated on a single point x of a space X.
:::

## The Spike-and-slab approach

- An indicator variable ($\delta$) is included in the prior to allow switching between the spike and slab  throughout the MCMC sampling process.

- For example, this allows for switching between a fixed effect $\tau^{\sigma} = 0$ ($\mathcal{M}_0$) and random effects model $\tau^{\sigma} > 0$ ($\mathcal{M}_u$)--i.e.,

:::fragment
\begin{equation}
\tau^{\sigma}_* = \begin{cases}
0, & \text{if }\delta = 0 , \\
\tau^{\sigma}, & \text{if }\delta = 1
\end{cases}
\end{equation}
:::

---

The posterior model probabilities can then be computed as

\begin{align}
Pr(\mathcal{M}_u | \textbf{Y}) = \frac{1}{S} \sum_{s = 1}^S \delta_s,
\end{align}

where $S = \{1,...,s\}$ denotes the posterior samples.

Assuming equal prior odds

\begin{align}
BF = \frac{1 - Pr(\mathcal{M}_u | \textbf{Y})}{Pr(\mathcal{M}_u | \textbf{Y})}
\end{align}


## Model formulation

### Likelihood

\begin{align}
\label{eq:likelihood}
y_{ij} & \sim  \mathcal{N}(\beta_{0j} + \beta_{1j}X_{ij}, \exp[\alpha_{0j} + \alpha_{1j}M_{ij}])
\end{align}

## Model formulation

### Location

\begin{align}
\beta_{0j} &= \gamma_{0} + \tau_{u_0}z^\mu_j\\
\beta_{1j} &= \gamma_{1} + \tau_{u_1}(\rho_{u_{0j}u_{1j}} + \sqrt{1-l_{21}^2})z^\mu_j\\
z^\mu &\sim \mathcal{N}(0,1) \\ 
\gamma_{u_0}, \gamma_{u_1} &\sim  \mathcal{N}(0, 1000)\\
\tau_{u_0}, \tau_{u_1} &\sim \mathcal{S}\boldsymbol{t}^{+}(\nu = 0, 1, 3)\\ 
\end{align}


$\tau^{\sigma}_*$ is the random effects standard deviation of the scale intercepts. This is where the spike and slab prior distribution is introduced.



---

\begin{align}
\label{eq:scale_ss}
\tau^{\sigma}_* &=  \delta \text{ } \cdot \text{ } \tau^{\sigma}  \\ \nonumber
\delta &\sim \text{Bernoulli}(\pi) \\ \nonumber
\tau^{\sigma} &\sim \mathcal{S}\boldsymbol{t}^{+}(\nu = 10, 0, 1)
\end{align}

For each MCMC iteration, a 0 or 1 is drawn from the Bernoulli distribution with the prior probability of sampling a 1 denoted $\pi$.

\begin{equation}
\tau^{\sigma}_* = \begin{cases}
0, & \text{if }\delta = 0 , \\
\tau^{\sigma}, & \text{if }\delta = 1
\end{cases}
\end{equation}

We set a prior of $\delta = 0.5$ to indicate lack of preference about inclusion or exclusion of a random effect.
---

The posterior model probabilities can then be computed as

\begin{align}
Pr(\mathcal{M}_u | \textbf{Y}) = \frac{1}{S} \sum_{s = 1}^S \delta_s,
\end{align}

where $S = \{1,...,s\}$ denotes the posterior samples.

Assuming equal prior odds

\begin{align}
BF_{0u} = \frac{1 - Pr(\mathcal{M}_u | \textbf{Y})}{Pr(\mathcal{M}_u | \textbf{Y})}
\end{align}

## The membership model

- So far we focused on whether there is evidence for a common within-person variance.

- We can ask then if there is evidence for a common ICC or reliability.

- If there is, which (or how many) individuals belong to the common variance model?

---

\begin{align}
\label{eq:mm}
\eta_{0i}^* &= z^\mu_i\rho  + z^\sigma_i\sqrt{1-\rho^2}  \\ \nonumber
\eta_{0i} &= \eta_0 + \tau^{\sigma} \big(\eta_{0i}^*  \text{ } \cdot \text{ } \delta_i\big) \\ \nonumber
z^\sigma_i &\sim \mathcal{N}(0,1) \\ \nonumber
\delta_i &\sim \text{Bernoulli}(\pi).
\end{align}

The subscript to the indicator ($\delta_i$) assigns each person a prior inclusion probability.

\begin{equation}
\label{eq:mm_delta}
\eta_{0i} = \begin{cases}
\eta_{0}, & \text{if }\delta_i = 0 , \\
\eta_0 + \tau^{\sigma}\left(z^\mu_i\rho  + z^\sigma_i\sqrt{1-\rho^2}\right), & \text{if }\delta_i = 1
\end{cases}.
\end{equation}

---

Individual $i$ is a member of the common ICC model when $\delta_i = 0$.

This specification allows each individual to have their own person-specific estimate or the fixed effect average. 

Each individual has a posterior probability of membership for belonging to the common ICC model.

Assuming equal prior odds

\begin{align}
\label{eq:bf_i}
BF_{0ui} = \frac{Pr(\eta_{0i} = \eta_0| \textbf{Y} )}{1 - Pr(\eta_{0i} = \eta_0| \textbf{Y} )}.
\end{align}

## Illustrative example

- The data for this empirical example come from the Highschool and Beyond study (Raudenbush & Bryk, 2002)

- We are interested in identifying clustering units (schools) that exhibit either unusually large or unusually small within-cluster variance – indicating either inconsistent or consistent academic achievement.

## Estimation


---
title: "Homework Week 7"
author: "Marwin Carmo"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---

```{r, message = FALSE, echo = FALSE}
## Load packages
library( ggplot2 )
library(bayesplot )
library( brms )
```
# Data

Data are from a study (March -- April 2020) on 86 patients infected with COVID-19 who were treated in the emergency department (ED) of Lausanne University Hospital, Switzerland. The first google hit on https://datasetsearch.research.google.com/
landed me on their page (I only noted afterwards that data are from Switzerland - nothing personal): https://zenodo.org/record/3763421

These data include a number of variables as well as a an outcome 7 days into entering the study. 
Here, we will use `fu7_death` as the outcome variable -- i.e., this variable records whether that study participant was alive or deceased by day 7.

The dataset is not really documented, but this is my guess of what these variables mean:
Outcome at day 7

 - `fu7_icu`: 1 = Intensive Care (lots of missings)
 - `fu7_iot`: 1 = Intubated (lots of missings)
 - `fu7_death`: 1 = Dead 

You are free to play around with these variables. 

The Other variables seem to have been recorded at the _entry_ to the study 7 days earlier and most of them are self explanatory. We will use some of them as predictors.

### Read in data 
Let's read in the data and peak into it 
```{r}
lus <- read.csv( file = "https://zenodo.org/record/3763421/files/Clinical_data.csv?download=1" )
head( lus, n =  5 )
```
### Subset Data 
Select some variables of interest -- note that some have lot's of missing values. That is, I selected mostly those with few missings.
So far, we haven't talked about ways to deal with missing values, hence, I dropped all missing values with `na.omit()`.

I also recoded sex to by dummy-coded with 0 = male, and 1 = female

```{r}
lus2 <- na.omit( lus[ !is.na( lus$fu7_death) , c("sex", "age",  "hbp", "diabetes", "heart_ischemia",
                                                 "asthma", "cp_bp_systolic",  "cp_bp_diastolic",
                                                 "cp_saturation", "creatine", "leukocytes",
                                                 "status_pulm", "fu7_death")] )
## Recode sex, to 0 = males, 1 = females
lus2$sex <- lus2$sex - 1

## Center continuous variables at their grand mean:
head(lus2 )
gmc <- scale(lus2[, c('age', 'cp_bp_systolic', 'cp_bp_diastolic', 'cp_saturation', 'creatine', 'leukocytes') ], center = TRUE, scale = FALSE)
colnames(gmc) <- paste0( colnames(gmc ), ".c")
lus2 <- data.frame(lus2, gmc)

## We're left with N = 61
nrow(lus2)
```

# Question 1 

We predict `fu7_death` as this variable seems to have relatively few missings by `sex`(0=male / 1=female), `age.c`,  and `heart_ischemia` (0=not present / 1=present: Heart ischemia is a reduced blood flow to the heart, mostly due to calcification in the arteries)

Try thinking about a model that is capable of predicting 0/1 coded output, write it up formally. Also think about what priors would make sense -- imagine that you'd be able to defend you prior choice in a review.
Later we will fit this model: `fu7_death ~ sex + age.c + heart_ischemia`, you can use those variables or keep it more general, such as using $x_1$, $x_2$, etc. as placeholders for your specific variables. 

### Answer:
Formal model:
\begin{align*}
y &\sim \text{Bernoulli}(p)\\
\text{logit}(p) &= \alpha + \beta_{sex} + \beta_{age_c} + \beta_{ischemia}\\
\alpha &\sim \mathcal{N}(0, 10)\\
\beta_{age_c} &\sim \mathcal{N}(0, 10)\\
\beta_{ischemia}&\sim \mathcal{N}(0, 10)
\end{align*}


## Hints {.tabset}

### Hint:
If you need a hint, click on the next tab 

### Hint/Solution: Formal Model

We are trying to predict the outcome `fu7_death` which is 0/1 coded. 0 is alive, 1 is dead.
A logistic regression seems to be a natural choice where some of the predictors will increase or decrease the odds of dying due to COVID related complications. 

As you may recall from  PSC-204B, logistic regressions are general linear models based on a Bernoulli distribution with a logit link $\log\left( \frac{p}{1 - p} \right)$. In terms of defining this model, we can write a generic model (without direct reference to certain predictors) as:
\begin{align*}
\text{Likelihood:} \hspace{1cm}	y &\sim Bern( \theta ) = 
		\begin{cases}
			\theta \text{ if } y = 1\\
			1 - \theta  \text{ if } y = 0
		\end{cases}
	\text{ where } \theta \in \{0,1\} \\
& logit( \theta ) = log\left(\frac{\theta}{1-\theta}\right) = \beta_0 + x_1\beta_1 + \ldots + x_p\beta_p =  \mathbf{X}\boldsymbol{\beta} \\
\text{ Prior for all elements in }\boldsymbol{\beta}\text{:} \hspace{1cm} \boldsymbol{\beta} &\sim \mathcal{N}(\mathbf{0}, 10\mathbf{I})
\end{align*}

In other words, our likelihood is defined as a Bernoulli function. Given the logit link that removes all bounds from our linear model, we can use relatively uninformed normal distributions for each of the $\beta$'s. Here, I chose a normal distribution with mean of zero and a standard deviation of 10 for each of the $\beta$'s

The next step is to write this model up in `brms`. 


# Question 2

 a) Now, take `sex`, `age`, and `heart_ischema` as predictors and `fu7_death` as the outcome and code it up in `brms`. Make sure the priors are reflecting the priors you defined in your formal model.
 *Interpret the model parameters.*

```{r "brms-model"}
names(lus2 )

## brms model:

fit1 <- brms::brm(fu7_death ~ sex + age.c + heart_ischemia,
          family = bernoulli(link = "logit"),
          data = lus2,
          prior = prior(normal(0, 10), class = Intercept) +
            prior(normal(0, 10), class = "b", coef = "sex") +
            prior(normal(0, 10), class = "b", coef = "age.c") +
            prior(normal(0, 10), class = "b", coef = "heart_ischemia")
          )

fit1
```

The log-odds of death when all predictors are zero is -3.65. This indicates a very low probability of death in the baseline category. The log-odds of death decreases by 0.83 for females compared to males. We can also see that for each unit increase in centered age, the log-odds of death increases by 0.06. Finally, having heart ischemia increases the log-odds of death by 3.00. All parameters have an $\hat{R}$ of 1.00, indicating good convergence of the chains.

 b) Fit another model that predicts `fu7_death`. For example, I chose `age.c`, `asthma`, `cp_saturation` as another set of predictors, but you can try different variables and/or variable combinations if you want.
 *Interpret the model parameters.*
 
```{r}
## brms model:

fit2 <- brms::brm(fu7_death ~ asthma + age.c + cp_saturation,
          family = bernoulli(link = "logit"),
          data = lus2,
          prior = prior(normal(0, 10), class = Intercept) +
            prior(normal(0, 10), class = "b", coef = "asthma") +
            prior(normal(0, 10), class = "b", coef = "age.c") +
            prior(normal(0, 10), class = "b", coef = "cp_saturation")
          )
fit2
```

The log-odds of death when all predictors are zero is 7.48. Having asthma decreases the log-odds of death by 7.77 compared to not having asthma. For each unit increase in centered age, the log-odds of death increases by 0.04. For each unit increase in capillary oxygen saturation, the log-odds of death decreases by 0.11. All parameters have an $\hat{R}$ of 1.00, indicating good convergence of the chains.


# Question 3: Check the model fit via _Posterior_ PD

Find a way to check whether your models fit the data. Note that eg. `ppc_dens_overlay()` is for continuous variables - here we have a discrete outcome. You may want to take some inspiration from here: https://mc-stan.org/bayesplot/reference/PPC-overview.html
```{r model-quality}

## Posterior Predictive Checks

## Model 1
pp1 <- brms::posterior_predict(fit1)
ppc_bars(lus2$fu7_death, pp1)

## Model 2
pp2 <- brms::posterior_predict(fit2)
ppc_bars(lus2$fu7_death, pp2)
```


# Question 3: Compare models

Compare your models to each other:

a) Use the `loo` library and comment on the model you would prefer.

```{r}
## code
library( loo )

loo_fit1 <- loo(fit1)
loo_fit2 <- loo(fit2)

loo_compare(loo_fit1, loo_fit2)
```
Model 1, since it has has a better predictive performance than Model 2 as seen by the negative `elpd_diff`. However, the difference is smaller than 4, so we can assume that the models have very similar predictive performance.

b) Now, compare the two models via the Bayes Factor. Comment on what you find. 

```{r}
## code
library(bridgesampling)
bf(bridge_sampler ( fit1 ) , bridge_sampler ( fit2 ))
```
Based on the large Bayes Factor, we have  strong evidence in favor of Model 1 compared to Model 2. The magnitude of these results is not comparable to the evidence obtained with LOO-CV, that gave us only borderline evidence in favor of Model 1.
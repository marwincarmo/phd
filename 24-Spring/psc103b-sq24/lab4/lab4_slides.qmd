---
title: "Lab 4: Chi Square Tests"
subtitle: "PSC 103B"
author: "Marwin Carmo"
format: 
  revealjs:
    scrollable: true
    incremental: true
    code-tools: true
    code-copy: true
    code-line-numbers: true
    code-link: true
    preview-links: true
    slide-number: true
    self-contained: true
    fig-height: 4
    fig-width: 6
    fig-align: center
    margin-left: "0"
    margin-right: "0"
    width: 1400
    callout-icon: false
    # height: 900
    footer: "PSC 103B - Statistical Analysis of Psychological Data"
    logo: "https://github.com/emoriebeck/psc290-data-viz-2022/raw/main/01-week1-intro/02-code/02-images/ucdavis_logo_blue.png"
editor: source
execute:
  echo: true
editor_options: 
  chunk_output_type: console
---

## Packages and data

First of all, lets load tidyverse

```{r}
library(tidyverse)
```

And read in the data with this "new" function

```{r}
cards <- read_rds('Lab4Data.rds')
```


:::.{note}
Today the data we'll use is in an .rds file. 
This is a type of R file that allows you to save a little bit more information with your dataframe or other object (for example, if you have a column full of numbers that you
want to be stored as type character instead, saving an .rds will
allow you to do that). The downside to .rds files is that
it's not possible to view it as easily outside of R,
like a .csv file is (you could simply open it using any
spreadsheet software).
:::

## Today's dataset

- 200 people were asked to imagine a shuffled deck of cards and mentally pick one card at random. 

- Then they were asked to randomly pick another card. 

- This data set records the suit choice for the first and second choices for each participant. 

- Participants didn't  physically pick a card, they were asked to imagine randomly picking a card.

## Today's dataset

```{r}
head(cards)
```

- `id`: participant ID
- `choice_1`: card suit for first pick 
- `choice_2`: card suit for second pick 

---

```{r}
table(cards$choice_1)
```

- Any inital impressions? 

- What would it look like if people chose cards randomly?

- Do people really choose cards randomly?

## Chi Square Goodness of Fit Test

- Let's say our theory is "people don't choose cards randomly" 

- $H_0$: All four suits are chosen with equal probability, or

- $H_0$: P = (P1, P2, P3, P4), where P is a vector or set of probabilities.

- If the suits are equally represented, what proportions do we expect?

- $H_0$: P = (.25, .25, .25, .25)

:::fragment
```{r}
H0_prob <- c(clubs = .25, diamonds = .25, hearts = .25, spades = .25)
```
:::

## Chi Square Goodness of Fit Test

- $H_1$: *At least one* of the suit-choice probabilities isn't .25. How would you write that? Remember that probabilities must sum to 1.

- $H_1$: P $\neq$ (.25, .25, .25, .25)

## Chi Square Goodness of Fit Test

- We can save our observed frequencies for the first choice in an object:

:::fragment
```{r}
observed_freq <- table(cards$choice_1)

observed_freq
```
:::

- We can compare these two pieces of information to test our H0.

## Chi Square Goodness of Fit Test

- We can transform the H0 probabilities into the frequencies we would expect to see if H0 were true

- First, we need to write our total sample size:

:::fragment
```{r}
N <- 200
```
:::

- And we can multiply this by our expected probabilities to get the expected frequencies:

:::fragment
```{r}
expected_freq <- H0_prob * N
expected_freq
```
:::

## Chi Square Goodness of Fit Test

$H_0$: P = (.25, .25, .25, .25)

$H_1$: P $\neq$ (.25, .25, .25, .25)

Look at the data again. Do you think H0 or H1 is more likely to be true?

```{r}
observed_freq
expected_freq
```

## Chi Square Goodness of Fit Test

- What we want to do now is compare the expected results with the observed results.

- If they are similar enough, we don't reject H0.

- If they are very different, we reject H0.

- But how do we know how far is **too far** from the expected values? 

## Chi Square Goodness of Fit Test

### Step 1: Compute "error" scores

```{r}
(error_scores <- (observed_freq - expected_freq)^2 / expected_freq)
```

Bigger numbers = more discrepancy between observed and expected frequency.

- We can use these error scores to calculate the goodness of fit statistic

:::fragment
```{r}
goodness_of_fit <- sum(error_scores) # This is our goodness of fit statistic
```
:::

## Chi Square Goodness of Fit Test

### Step 1: Compute "error" scores

The closer the observed frequencies are to the prediction by H0 (expected frequencies), the __________ the goodness of fit statistic will get. [Larger or smaller?]

- Larger!

- How large is large enough to reject H0?

## Chi Square Goodness of Fit Test

### Step 2: Compare our statistic to the chi-square distribution

```{r echo=FALSE}

x1 <- seq(0, 30, by = .1)
y_df5 <- dchisq(x = x1, df = 5)
y_df10 <- dchisq(x = x1, df = 10)
y_df15 <- dchisq(x = x1, df = 15)

tibble(x1, y_df5, y_df10, y_df15) %>%
  pivot_longer(-x1, names_to = "dfs", names_prefix = "y_df", values_to = "value") %>%
  mutate(dfs = ordered(dfs, levels = c(5, 10, 15))) %>% 
  ggplot(aes(x = x1, y = value, color = dfs)) +
  geom_line(size = 1.5, alpha = .9) +
  labs(x = "", y = "density") +
  theme_classic()
```


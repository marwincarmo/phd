---
title: "Using MELSM to Identify Consistent and Inconsistent Schools"
author: "Marwin Carmo"
#date: "2025-02-14"
execute: 
  message: false
  warning: false
format: 
  pdf:
    documentclass: report
    fig-height: 4
    fig-width: 6
    bm: true
    amsmath: true
    mathspec: true
            
---

## Background

Mixed-effects location-scale models (MELSM) are an extension of standard mixed-effects models, such that the residual variance is not assumed to be constant but can be modeled, allowing the inclusion of a sub-model to address potential differences in the residual variance. The MELSM estimates simultaneously a model for the means (location) and a model for residual variance (scale). For instance, in an educational research setting, the model defines a multilevel mode for the observed values, $y_{ij}$, for school $j$ and student $i$, and a multilevel model for the within-school residual variances, $\sigma_{ij}$.

Based on the MESLM ability to estimate residual standard deviations, we can implement the spike-and-slab regularization technique to the scale random effects to identify schools (clusters) whose student-level residual standard deviations are not captured well by scale fixed effects. The idea is to place an indicator variable, $\delta \in$ [0, 1], to the random effects to be subjected to shrinkage where the school-level effect for the scale either retains the random effect or reduces to the fixed effect, according to $\delta$â€™s value. So, for each $j$ school and $k$ random effect, a posterior inclusion probability (PIP) is computed to quantify the probability that a given random effect is included in the model, conditional on the observed data. A PIP greater than 0.75 indicates strong evidence that the school's residual variability deviates significantly from the average due to higher or lower consistency in student performance. This method is termed Spike and slab mixed-effects location-scale model (SS-MELSM) and is implemented the R package `ivd`.

## Research question

The motivation for the SS-MELSM is to identify and isolate clusters that display unusual amounts of residual variability. It shares the same general approach of modeling residual variances in a MELSM, such as studying variables that contribute to (in)consistency. The focus, however, is on the \textit{identification} of clustering units that show unusually high or low consistency in academic achievement. It is expected that the clusters attributed PIPs higher than 0.75 have a distinct pattern of within-cluster variability that clearly distinct them from others.

## Method

The data for this study comes from The Elementary Education Evaluation System (Saeb), an assessment program conducted by the Brazilian government to evaluate the quality of elementary education across the country. This dataset contains standardized math test scores from 11,386 11th and 12th graders across 160 schools and is part of the `ivd` package. 

To keep this illustration simple, I opted for a model that features an intercept-only specification in both the location and scale submodels. The model predicting math achievement for the $i$-th student within the $j$-th school is:

\begin{equation}
\label{eq:model-1}
\begin{aligned}
\text{mAch}_{ij} & \sim  \mathcal{N}(\mu_j, \sigma_j)\\
\mu_j &= \gamma_{0} + u_{0j}\\
\sigma_j &= \exp(\eta_{0} + t_{0j})
\end{aligned}
\end{equation}


\begin{equation} \nonumber
  \textbf{v}=
  \begin{bmatrix} u_0 \\ t_0 \end{bmatrix} \sim \mathcal{N}
    \begin{pmatrix}
        \boldsymbol{0}=
        \begin{bmatrix} 0 \\ 0 \end{bmatrix},
        \boldsymbol{\Sigma}=
        \begin{bmatrix} \tau^2_{u_0} & \tau_{u_0t_0} \\ 
                        \tau_{u_0t_0} & \tau^2_{t_0} 
        \end{bmatrix}
    \end{pmatrix}
\end{equation}

This model defines math achievement ($\text{mAch}_{ij}$) via the fixed intercept parameter $\gamma_0$ and the random intercept $u_{0j}$, capturing the deviation of the $j$-th school from the fixed effect. Each school's residual standard deviation is modeled as a function of the fixed effect $\eta_0$ and the school-specific deviation $t_{0j}$, both defined on the log scale.

The random effects are assumed to come from the same multivariate Gaussian Normal distribution with zero means and covariance matrix $\boldsymbol\Sigma$. This matrix can be decomposed into $\boldsymbol\Sigma = \boldsymbol{\tau}\boldsymbol{\Omega\tau}'$, where $\boldsymbol{\tau}$ is a diagonal matrix holding the random-effect standard deviations and $\boldsymbol\Omega$ is the correlation matrix that contains the correlations among all random effects. Next, we can decompose $\boldsymbol\Omega$ via the Cholesky factor $\textbf{L}$ of $\boldsymbol\Omega = \textbf{L}'\textbf{L}$.

With these decomposition, the random effects vector $\textbf{v}$ by multiplying $\textbf{L}$ with the standard deviations $\boldsymbol{\tau}$ and scaling it with a standard normally distributed $\textbf{z}_j$. Then, it can be expanded to include an indicator vector $\boldsymbol{\delta}_j$ of length $k$ (for $1, \ldots, k$ random effects) for each random effect to be subjected to shrinkage:

\begin{equation} \label{eq:ss_v}
\textbf{v}_j = \boldsymbol{\tau}\textbf{L}\boldsymbol{z}_j\boldsymbol{\delta}_j.
\end{equation}

Each element in $\boldsymbol{\delta}_j$ takes integers $\in \{0,1\}$ and follows a $\delta_{jk} \sim \text{Bernoulli}(\pi=0.5)$ distribution. Depending on $\delta$'s value, the computations in Equation \eqref{eq:ss_v} will either retain the random effect or shrink it to exactly zero. Consequently, the estimated posterior inclusion probability (PIP) quantifies the probability that a given random effect is included in the model, conditional on the observed data. The PIP of any random effect $k$ is determined by the proportion of MCMC samples where $\delta_{jk} = 1$ across the the total number of posterior samples $S$:
\begin{align}
\label{eq:pip}
Pr(\delta_{jk} = 1 | \textbf{Y}) = \frac{1}{S} \sum_{s = 1}^S \delta_{jks}.
\end{align}

Setting the prior probability of $\pi$ to 0.5 implies equal prior odds, $Pr(\delta_{jk} = 1)/Pr(\delta_{jk} = 0) = 1$, reflecting no prior information about the presence of a random effect. The Bayes factor for including the $k$th random effect in the $j$th school simplifies to:
\begin{align}
\label{eq:bf_pip}
BF_{10_{jk}} = \frac{Pr(\delta_{jk} = 1 | \textbf{Y}) }{1 - Pr(\delta_{jk} = 1 | \textbf{Y}) }.
\end{align}

A posterior inclusion probability $Pr(\delta_j = 1|\textbf{Y}) \geq 0.75$, corresponding to a $BF_{10_{jk}} \geq 3$, provides evidence for including the random effect over fixed effects alone.

This model was fitted using the `ivd` package using six chains of 3,000 iterations and 12,000 warm-up samples. The results present the posterior estimates of: (i) the PIP for $\delta_{jt_0}$, (ii) the scale random effect SD, $\tau_{t_0}$, (iii) within-school residual SD, $\sigma_j$, and (iv) the math scores, $\mu_j$.

## Results

The location model yielded an intercept fixed effect of $\gamma_0=0.115$ (95\% CrI [0.055; 0.174]). This suggests that, on average, schools in this sub-sample performed slightly above the standardized mean score of the larger sample of schools from which it was drawn. In the scale model, the estimated intercept of the residual standard deviation was $\eta_0=-0.235$ (95\% CrI [-0.253; -0.217]) on the log scale. This corresponds to a mean of $\exp(-0.235)=0.791$ on the standard deviation metric. @fig-pip displays the 160 PIPs for all schools. Notably, eight schools exhibited PIPs greater than 0.75, as indicated by the colored points above the dotted line. These PIPs suggest significant deviations from the average school-level variance. 

@fig-funnel, panel A, shows the distribution of within-school residual standard deviations. Among the eight identified schools, five exhibited lower-than-average standard deviations, indicating \textit{higher consistency} in student performance. Conversely, the remaining three schools showed greater variability, reflected by their positioning farther to the right and above the dotted line, indicating \textit{lower consistency} (larger standard deviations) in math achievement for these schools. This pattern is further elucidated in panel B, which shows a scatterplot of school PIPs to their average math scores. School 46 was not only highly consistent in math achievement, but they also performed better than the average in our sample. We can also observe a mix of more inconsistent and consistent schools within 0.5 standard deviations of the mean. While the average math achievement of these schools is comparable, the within-school variability was substantially different.

@fig-sugarloaf shows the posterior distributions of the scale random intercept for the eight shcools with PIP > 0.75. Panel A shows the posterior distribution of $t_{0j}$ and in panel B, the posterior of $\sigma_j$. The pattern is similar given that $\sigma_j$ is a function of $t_{0j}$. Notably, the estimates of schools 46 and 39, respectively the more consistent and inconsistent schools in the sample, ``escaped'' the pull of the spike. For other schools, as the PIP of $\delta_{0j}$ got closer to 0.75, we can observe a significant posterior mass of $t_{0j}$ on the spike, although a notable portion remains in the slab. These are characteristics of moderate evidence favoring the inclusion of the random effect.

```{r}
#| eval: true
#| include: false
library(ggplot2)
library(patchwork)
pip <- readRDS("plots/pip.rds")
funnel <- readRDS("plots/funnel.rds")
outcome <- readRDS("plots/outcome.rds")
ranef <- readRDS("plots/ranef.rds")
sigma <- readRDS("plots/sigma.rds")
```

## Visualization

```{r}
#| label: fig-pip
#| echo: false
#| message: false
#| warning: false
#| fig-align: center
#| fig-cap: The posterior inclusion probabilities of the scale random effect for the 160 schools in the dataset for Models 1 and 2. A dotted line marks the PIP threshold of 0.75. Schools with PIPs exceeding this threshold are colored and labeled.
#| fig-height: 4
#| fig-width: 6
pip 
```

```{r}
#| label: fig-funnel
#| echo: false
#| fig-cap: Scatter plots of posterior inclusion probability (PIP) versus within-cluster standard deviation (panel A) and math achievement (panel B). The y-axis represents the PIP for the scale random intercept. In panel A, the x-axis represents the estimated within-cluster SD, and in panel B, the estimated math achievement. In panel A, the plot exhibit a V-shaped pattern, where schools with the lowest and highest SDs are positioned toward the left and right, respectively. In panel B, the color shade represent the school's within-cluster SD.
#| fig-height: 7
#| fig-width: 6
funnel / outcome + 
  plot_annotation(tag_levels = 'A',title = "")
```

```{r}
#| label: fig-sugarloaf
#| echo: false
#| fig-cap: Density plots of the posterior estimates of the scale random effect (panel A), and cluster SD for schools with PIP for the inclusion of the scale random effect larger than 0.75. Schools with lower PIP show more posterior mass of $t_0$ on the spike (panel A) and, consequently, more posterior mass on the average residual standard deviation. In both panels, color shading represent the limits of posterior probability density.
#| fig-height: 7
#| fig-width: 6
ranef / sigma
```

## Visualization strategies

In this project I created five ways to visualize the posterior distribution of estimates produced by the `ivd` model. They were designed to complement the information provided by the model's summary by focusing on the schools with PIPs exceeding the proposed threshold of "significance."

For all plots, color was used to highlight and distinguish particular schools. In @fig-pip and both panels of @fig-funnel, those with unusual levels of variability were colored to emphasize that these are the relevant units, opposed to the gray shade given to schools with "average" variability that do not provide relevant information to the purposes of the analysis. In previous versions of these plots, a unique color was assigned to each high-PIP school to distinguish them. Now all high-PIP schools have the same color and are identified by direct labeling. Given the number of high-PIP schools, different colored points led to too many different colors to distinct. Adding colors *and* direct labels resulted in irrelevant information being displayed, given that colors now were not needed to distinguish the points.

Particularly to panel B in @fig-funnel, a sequential color scale was used to indicate which schools have more or less within-cluster standard deviation than other ones. In a previous version of this plot size was used to encode this difference. However, that provided only limited information given the difficulty of differentiating sizes that were similar and also for the challenge of setting up a proper legend guide to interpret the different sizes. Additionally, very consistent schools, such as 46, were represented by points that were too small to be seen. Switching to a sequential color scale provided a clearer visualization of the points and better represented the idea of a continuous scale.

<!-- Use direct labeling instead of colors when you need to distinguish between more than about eight categorical items.  -->

<!-- Then, unique colors were attributed for each of these high-PIP schools using a qualitative color scale produced by the `randomcoloR` package. In this paper's example, there were only eight high-PIP schools, but there is no limit to the number of clusters with unnusual variability and, consequently, to the colors needed. Using the `distinctColorPalette()` function ensures that colors optimally distinct will be attributed to these clusters, irrespective of how many are needed. -->

@fig-funnel shows the associations among PIPs and $\tau_{t_0}$ and $\mu_j$ represented by scatterplots. Although no trends are expected to be seen, this option was chosen to give a quick snapshot of how schools with high PIP are located across the within-cluster SD and the cluster mean spectrum. Similarly, the plot in @fig-pip glances on the distribution of estimated PIPs.

The plots from @fig-sugarloaf were designed to visualize uncertainty of point estimates. I opted for ridgeline plots to facilitate the comparison of the posterior distribution of the residual standard deviation of the high-PIP schools, emphasizing that more uncertainty (lower PIP) is a result of more posterior mass on the spike. Also, had the model identified a larger number of schools with unusual variability, ridgeplots could scale well to more distributions. In these plots, a sequential color scale was used to distinguish regions of posterior probabilities. The increasing shade of the blue color was used to indicate that the probability density is higher closer to the posterior mean and lower on the tails. 